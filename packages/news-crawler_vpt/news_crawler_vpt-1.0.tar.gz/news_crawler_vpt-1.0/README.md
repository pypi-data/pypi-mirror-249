
# News Crawler - CodeAcademy Artificial Intelligence student program

## About the Project
This project is the first assessment project in the CodeAcademy artificial intelligence training program. It was designed to demonstrate data collection and processing skills using Python, showcasing the ability to extract, categorize, and store information from online sources effectively.

## Functionality
The project includes several main scripts:

- `category_crawler.py`: Browses a specified website, extracts company categories, and saves them in a CSV file.
- `data_ex.py`: Responsible for extracting data from the website according to categories and printing the data in the console.
- `main.py`: The main script, managing the entire process from category acquisition to data extraction and storage.

## How to Use
To use this program, follow these steps:

1. Ensure you have the necessary libraries installed: `selenium`, `requests`, `lxml`. The list can be found in the `pyproject.toml` file.
2. Run the `main.py` script.
3. Follow the console instructions to control the data collection process.

## Author
This project was created by Vilmantas Pielikis, a student in the CodeAcademy AI training program, demonstrating a practical application of web scraping and data handling techniques in Python.

## License
This project is available for use subject to the author's permission. For any commercial or academic use, or for modifications and distribution, please obtain explicit permission from the author. This approach ensures responsible usage and maintains the integrity of the project.
