Metadata-Version: 2.1
Name: python-tgpt
Version: 0.0.9
Summary: Interact with AI without API key
Home-page: https://github.com/Simatwa/python-tgpt
Author: Smartwa
Author-email: simatwacaleb@proton.me
Maintainer: Smartwa
License: MIT
Project-URL: Bug Report, https://github.com/Simatwa/python-tgpt/issues/new
Project-URL: Homepage, https://github.com/Simatwa/python-tgpt
Project-URL: Source Code, https://github.com/Simatwa/python-tgpt
Project-URL: Issue Tracker, https://github.com/Simatwa/python-tgpt/issues
Project-URL: Download, https://github.com/Simatwa/python-tgpt/releases
Project-URL: Documentation, https://github.com/Simatwa/python-tgpt/blob/main/docs
Keywords: chatgpt,gpt,tgptchatgpt-cli,chatgpt-sdk,chatgpt-api,llama-api
Classifier: License :: OSI Approved :: MIT License
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Developers
Classifier: Natural Language :: English
Classifier: License :: Free For Home Use
Classifier: Intended Audience :: Customer Service
Classifier: Programming Language :: Python
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests ==2.28.2
Requires-Dist: click ==8.1.3
Requires-Dist: rich ==13.3.4
Requires-Dist: clipman ==3.1.0
Requires-Dist: pyperclip ==1.8.2

<h1 align="center"> python-tgpt </h1>

<p align="center">
<!--
<a href="https://github.com/Simatwa/python-tgpt/actions/workflows/python-test.yml"><img src="https://github.com/Simatwa/python-tgpt/actions/workflows/python-test.yml/badge.svg" alt="Python Test"/></a>
-->
<a href="https://github.com/Simatwa/python-tgpt/blob/main/LICENSE"><img alt="License" src="https://img.shields.io/static/v1?logo=GPL&color=Blue&message=MIT&label=License"/></a>
<a href="https://pypi.org/project/python-tgpt"><img alt="PyPi" src="https://img.shields.io/static/v1?logo=pypi&label=Pypi&message=v0.0.9&color=green"/></a>
<a href="https://github.com/psf/black"><img alt="Black" src="https://img.shields.io/static/v1?logo=Black&label=Code-style&message=Black"/></a>
<a href="#"><img alt="Passing" src="https://img.shields.io/static/v1?logo=Docs&label=Docs&message=Passing&color=green"/></a>
<a href="https://github.com/Simatwa/python-tgpt/actions/workflows/python-package.yml"><img src="https://github.com/Simatwa/python-tgpt/actions/workflows/python-package.yml/badge.svg"/></a>
<a href="#"><img alt="coverage" src="https://img.shields.io/static/v1?logo=Coverage&label=Coverage&message=90%&color=yellowgreen"/></a>
<a href="#" alt="progress"><img alt="Progress" src="https://img.shields.io/static/v1?logo=Progress&label=Progress&message=95%&color=green"/></a>
<a href="https://pepy.tech/project/tgpt2"><img src="https://static.pepy.tech/personalized-badge/tgpt2?period=total&units=international_system&left_color=grey&right_color=green&left_text=Downloads" alt="Downloads"></a>
<a href="https://pepy.tech/project/python-tgpt"><img src="https://static.pepy.tech/personalized-badge/python-tgpt?period=total&units=international_system&left_color=grey&right_color=blue&left_text=Downloads" alt="Downloads"></a>
<!--<a href="https://github.com/Simatwa/python-tgpt/releases"><img src="https://img.shields.io/github/downloads/Simatwa/python-tgpt/total?label=Downloads&color=success" alt="Downloads"></img></a> -->
<a href="https://github.com/Simatwa/python-tgpt/releases"><img src="https://img.shields.io/github/v/release/Simatwa/python-tgpt?color=success&label=Release&logo=github" alt="Latest release"></img></a>
<a href="https://github.com/Simatwa/python-tgpt/releases"><img src="https://img.shields.io/github/release-date/Simatwa/python-tgpt?label=Release date&logo=github" alt="release date"></img></a>
<a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com/Simatwa/python-tgpt"/></a>      
<a href="https://wakatime.com/badge/github/Simatwa/tgpt2"><img src="https://wakatime.com/badge/github/Simatwa/tgpt2.svg" alt="wakatime"></a>
</p>

<p align="center">
AI for all
</p> 

<p align="center">
<img src="https://github.com/Simatwa/python-tgpt/blob/main/assets/console-demo.gif?raw=True" width='100%'/>
</p>


```python
>>> import tgpt
>>> bot = tgpt.TGPT()
>>> bot.chat('Hello there')
"  Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?"
>>> 
```

This project enables seamless interaction with [LLaMA](https://ai.meta.com/llama/) AI without requiring an API Key.

The name *python-tgpt* draws inspiration from its parent project [tgpt](https://github.com/aandrew-me/tgpt), which operates on [golang](https://go.dev/). Through this Python adaptation, users can effortlessly engage with LLaMA's capabilities, fostering a smoother AI interaction experience.

## Prerequisites

- [x] [Python>=3.9](https://python.org)

## Installation and Usage

### Installation

Choose one of the following methods to get started.

1. From PyPI:

   ```bash
   pip install --upgrade python-tgpt
   ```

2. Directly from the source:

   ```bash
   pip install git+https://github.com/Simatwa/python-tgpt.git
   ```

3. Clone and Install:

   ```bash
   git clone https://github.com/Simatwa/python-tgpt.git
   cd python-tgpt
   pip install .
   ```

## Usage

This package offers a convenient command-line interface.

- For a quick response:
  ```bash
  python -m tgpt generate "<Your prompt>"
  ```

- For interactive mode:
  ```bash
  python -m tgpt interactive "<Kickoff prompt (though not mandatory)>"
  ```

You can also simply use `tgpt` instead of `python -m tgpt`.

Starting from [version 0.0.6](https://github.com/Simatwa/python-tgpt/releases), `generate` is the default command. Therefore, something like this will still work: `tgpt "<Your prompt>"`.

<details>

<summary>

### Developer Docs

</summary>

1. Generate a quick response

```python
from tgpt import TGPT
bot = TGPT()
resp = bot.chat('<Your prompt>')
print(resp)
# Output : How may I help you.
```

2. Get back whole response

```python
from tgpt import TGPT
bot = TGPT()
resp = bot.ask('<Your Prompt')
print(resp)
# Output
"""
{'completion': "I'm so excited to share with you the incredible experiences...", 'stop_reason': None, 'truncated': False, 'stop': None, 'model': 'llama-2-13b-chat', 'log_id': 'cmpl-3NmRt5A5Djqo2jXtXLBwJ2', 'exception': None}
"""
```

#### Stream Response 

Just add parameter `stream` with value  `true`.

1. Text Generated only 

```python
from tgpt import TGPT
bot = TGPT()
resp = bot.chat('<Your prompt>', stream=True)
for value in resp:
    print(value)
# output
"""
How may
How may I help 
How may I help you
How may I help you today?
"""
```

2. Whole Response

```python
from tgpt import TGPT
bot = TGPT()
resp = bot.ask('<Your Prompt>', stream=True)
for value in resp:
    print(value)
# Output
"""
{'completion': "I'm so", 'stop_reason': None, 'truncated': False, 'stop': None, 'model': 'llama-2-13b-chat', 'log_id': 'cmpl-3NmRt5A5Djqo2jXtXLBwxx', 'exception': None}

{'completion': "I'm so excited to share with.", 'stop_reason': None, 'truncated': False, 'stop': None, 'model': 'llama-2-13b-chat', 'log_id': 'cmpl-3NmRt5A5Djqo2jXtXLBwxx', 'exception': None}

{'completion': "I'm so excited to share with you the incredible ", 'stop_reason': None, 'truncated': False, 'stop': None, 'model': 'llama-2-13b-chat', 'log_id': 'cmpl-3NmRt5A5Djqo2jXtXLBwxx', 'exception': None}

{'completion': "I'm so excited to share with you the incredible experiences...", 'stop_reason': None, 'truncated': False, 'stop': None, 'model': 'llama-2-13b-chat', 'log_id': 'cmpl-3NmRt5A5Djqo2jXtXLBwxx', 'exception': None}
"""
```


</details>

<details>

<summary>

- To get better feedback, you can make use of [optimizers](tgpt/utils.py) using parameter `optimizer` with values *(code or system_command)*

</summary>

```python
from tgpt import TGPT
bot = TGPT()
resp = bot.ask('<Your Prompt>', optimizer='code')
print(resp)
```

</details>



**Note**: Starting from [v0.0.7](https://github.com/Simatwa/python-tgpt/releases/), we've introduced an experimental conversational chatting feature:

```python
bot = tgpt.TGPT(is_conversation=True)
```

When interacting via the console, simply append the `--conversation` flag. Customize the `history_offset` parameter during the initialization of `TGPT` and utilize the `--history-offset` flag at the console entry point for the same.

This conversational mode opens up a more interactive and engaging experience, allowing greater control over the chat history's handling for a more tailored conversation.


## Acknowledgements

1. [x] [tgpt](https://github.com/aandrew-me/tgpt)
2. [x] You

