interactions:
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello, who are you?"}], "model": "gpt-3.5-turbo",
      "temperature": 1.0, "top_p": 1.0, "frequency_penalty": 0.0, "presence_penalty":
      0.0, "user": "", "stop": null, "max_tokens": 1}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-Length:
      - '283'
      content-Type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.5.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.5.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.10.13
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-7i3UPS1ZGAuO30Rqrcp4oI1Tuomtv\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1690734201,\n  \"model\": \"gpt-3.5-turbo-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Hello\"\n      },\n      \"finish_reason\":
      \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 23,\n    \"completion_tokens\":
      1,\n    \"total_tokens\": 24\n  }\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 7eeef2139b4a4aa8-TPE
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Sun, 30 Jul 2023 16:23:21 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-3.5-turbo-0613
      openai-processing-ms:
      - '169'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '3500'
      x-ratelimit-limit-tokens:
      - '90000'
      x-ratelimit-remaining-requests:
      - '3499'
      x-ratelimit-remaining-tokens:
      - '89985'
      x-ratelimit-reset-requests:
      - 17ms
      x-ratelimit-reset-tokens:
      - 10ms
      x-request-id:
      - 037f3b4947d1950cc4b89c9c77cffbb8
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Hello, who are you?"}], "model": "gpt-3.5-turbo",
      "frequency_penalty": 0.0, "max_tokens": 1, "presence_penalty": 0.0, "stop":
      null, "temperature": 1.0, "top_p": 1.0, "user": ""}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '283'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.5.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.5.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.10.13
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-8XOfRJC0Fitnq1uqkhdhEYCECFt0T\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1702970337,\n  \"model\": \"gpt-3.5-turbo-0613\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Hello\"\n      },\n      \"logprobs\":
      null,\n      \"finish_reason\": \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      23,\n    \"completion_tokens\": 1,\n    \"total_tokens\": 24\n  },\n  \"system_fingerprint\":
      null\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 837ddfdfd8566a84-TPE
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 19 Dec 2023 07:18:57 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=z7hMYGBZQIm78RjNCZxyI8c.BS6z.EhSVQWW3qBJrMk-1702970337-1-Ad9T5uuU2WnygqHw3AlANmj2V7LCyq4YpO6I8kxKt6PdUtkhTwonSn6IkWC3hAJIvJ36Lnqye1FrFZuNKzJHm3E=;
        path=/; expires=Tue, 19-Dec-23 07:48:57 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=1kA49xg..7.F0WPfpp3Gz7RbuK03qIXoVvXszOfK6Hg-1702970337868-0-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-3.5-turbo-0613
      openai-processing-ms:
      - '119'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '2000000'
      x-ratelimit-limit-tokens_usage_based:
      - '2000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '1999985'
      x-ratelimit-remaining-tokens_usage_based:
      - '1999985'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-ratelimit-reset-tokens_usage_based:
      - 0s
      x-request-id:
      - 0777330f20831d0baae989d0e0f52fc9
    http_version: HTTP/1.1
    status_code: 200
version: 1
