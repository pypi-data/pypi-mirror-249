{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57beea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc56f7-5e1e-4b9b-a2ec-a897d6397687",
   "metadata": {},
   "source": [
    "## Save a bunch of pipelines to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ngautonml.problem_def.problem_def import ProblemDefinition\n",
    "from ngautonml.wrangler.wrangler import Wrangler\n",
    "from ngautonml.wrangler.dataset import Dataset, DatasetKeys\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "try:\n",
    "    dirpath = str(Path(__file__).parent)\n",
    "except NameError:\n",
    "    dirpath = str('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0036e51f",
   "metadata": {},
   "source": [
    "<h2>Problem Definition</h2>\n",
    "\n",
    "All values are case-independent. The data format is `json`.\n",
    "\n",
    "We currently output predictions, trained models, and instantiations to memory, or to disk in our JSON format.\n",
    "\n",
    "This problem definition specifies a `JSON` instantiator in the `output` clause, so that all the pipelines and their trained models are saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca64aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_definition = ProblemDefinition(\n",
    "'{'\n",
    "'    \"_comments\" : ['\n",
    "'        \"A json file fully encapsulating the problem definition for openml dataset #31.\",'\n",
    "'        \"This dataset is a tabular binary classification problem.\",'\n",
    "'        \"People are classified as good or bad credit risks based on attributes.\"'\n",
    "'    ],'\n",
    "'    \"dataset\" : {'\n",
    "'        \"config\" : \"local\",'\n",
    "f'        \"test_path\": \"{dirpath}/examples/classification/credit-test.csv\",'\n",
    "f'        \"train_path\" : \"{dirpath}/examples/classification/credit-train.csv\",'\n",
    "'        \"column_roles\": {'\n",
    "'            \"target\": {'\n",
    "'                \"name\": \"class\"'\n",
    "'            }'\n",
    "'        }'\n",
    "'    },'\n",
    "'    \"problem_type\" : {'\n",
    "'        \"data_type\": \"TABULAR\",'\n",
    "'        \"task\": \"BINARY_CLASSIFICATION\"'\n",
    "'    },'\n",
    "'    \"metrics\" :  {'\n",
    "'        \"accuracy_score\": {},'\n",
    "'        \"roc_auc_score\": {}'\n",
    "'    },'\n",
    "'    \"output\" : {'\n",
    "f'       \"path\" : \"{dirpath}/output/classification/credit-output\",'\n",
    "'            \"instantiations\": ['\n",
    "'                \"JSON\"'\n",
    "'            ]'\n",
    "'    },'\n",
    "'    \"hyperparams\": ['\n",
    "'        \"disable_grid_search\"'\n",
    "'    ]'\n",
    "'}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e24dc-ea27-4550-8810-3edc8302418f",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5299c4-d97f-4aa4-bb14-fcc198473606",
   "metadata": {},
   "source": [
    "## Minimal example: the Wrangler\n",
    "The `wrangler` puts all the pieces together. In this example, we allow all components to default. The `wrangler.fit_predict_rank()` method runs all pipelines described from the problem definition and ranks them for each requested metric. The problem def saves all tested pipelines to `examples/classification/credit-output/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8514d8e-dd12-4190-8ee4-97cea79ddf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangler = Wrangler(\n",
    "    problem_definition=problem_definition,\n",
    ")\n",
    "\n",
    "got = wrangler.fit_predict_rank()\n",
    "print(got.train_results)\n",
    "summary = 'The rankings are:\\n'\n",
    "for rank in got.rankings:\n",
    "    summary = f'{summary} {rank}\\n'\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae537c7bad7a286962624bb706685d70455be40ce63f4435480ecca55813e257"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
